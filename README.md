# Proyecto de Aprendizaje Supervisado: Supervivencia en el Titanic

[![Hybridge Education](https://img.shields.io/badge/Hybridge%20Education-FFD700?style=for-the-badge&logoColor=black)](https://www.hybridge.education)

### IngenierÃ­a en Inteligencia Artificial - Clase de Inteligencia Artificial

Este repositorio documenta el proceso completo de un proyecto de aprendizaje supervisado, utilizando el famoso conjunto de datos del Titanic. El objetivo principal es aplicar los conceptos y metodologÃ­as fundamentales de la Inteligencia Artificial y el Machine Learning para predecir si un pasajero sobreviviÃ³ o no al desastre.

> Fecha de FinalizaciÃ³n: **23 de Septiembre del 2025**.

## ðŸš€ Flujo de Trabajo en Aprendizaje Supervisado

El proyecto sigue un flujo de trabajo estructurado que abarca desde la preparaciÃ³n inicial de los datos hasta la puesta en producciÃ³n de un modelo predictivo. A continuaciÃ³n se presenta un diagrama que ilustra este proceso, seguido de una explicaciÃ³n detallada de cada etapa.

```mermaid
graph TD;
    A[ðŸ“Š Dataset Inicial] --> B(ðŸ§¹ Limpieza de Datos);
    B --> C(ðŸ“ˆ AnÃ¡lisis Exploratorio);
    C --> D(ðŸ› ï¸ Feature Engineering);
    D --> E(ðŸ”ª DivisiÃ³n de Datos);

    subgraph "Fase de Modelado"
        E --> F[ðŸš„ Datos de Entrenamiento];
        E --> G[ðŸ§ª Datos de Prueba];
        F --> H(ðŸ§  Entrenamiento del Modelo);
        H --> I{ðŸ¤– Modelo Entrenado};
        I -- Predicciones --> J(ðŸ’¯ EvaluaciÃ³n del Modelo);
        G -- Datos reales --> J;
        J -. MÃ©tricas -> Reentrenar? .-> H;
    end

    subgraph "Fase de OperaciÃ³n"
        I --> K(ðŸš¢ Puesta en ProducciÃ³n);
    end

    style K fill:#cde4ff,stroke:#333,stroke-width:2px;
```

### ðŸ“š Conceptos Clave y Etapas del Proyecto

#### 2.1 Limpieza de Datos

- **Concepto:** Es el proceso fundamental de identificar y corregir (o eliminar) errores, inconsistencias y valores faltantes en un conjunto de datos. La calidad de un modelo de Machine Learning depende directamente de la calidad de los datos con los que se entrena, por lo que este paso es crucial para garantizar la fiabilidad de las predicciones.
    
- **AplicaciÃ³n en el proyecto (`1_clean.ipynb`):** Se manejaron valores nulos en columnas crÃ­ticas como `Age` y `Cabin`, se corrigieron tipos de datos y se eliminaron columnas que no aportaban informaciÃ³n relevante para el modelo.
    

#### 2.2 AnÃ¡lisis Exploratorio de Datos (EDA)

- **Concepto:** Consiste en analizar y visualizar los datos para descubrir patrones, anomalÃ­as, probar hipÃ³tesis y entender las relaciones entre las distintas variables. El EDA nos permite obtener una intuiciÃ³n profunda sobre el dataset antes de construir el modelo.
    
- **AplicaciÃ³n en el proyecto (`2_EDA.ipynb`):** Se generaron visualizaciones para entender cÃ³mo variables como la clase del pasajero (`Pclass`), el sexo (`Sex`) y la tarifa (`Fare`) se correlacionaban con la probabilidad de supervivencia (`Survived`).
    

#### 2.3 Feature Engineering

- **Concepto:** Es el proceso de utilizar el conocimiento del dominio para transformar variables existentes o crear nuevas (features) que mejoren el rendimiento del modelo. El objetivo es presentar la informaciÃ³n de una manera que sea mÃ¡s fÃ¡cil de entender para los algoritmos de aprendizaje.
    
- **AplicaciÃ³n en el proyecto (`3_feature_engineering.ipynb`):** Se convirtieron variables categÃ³ricas (como `Sex` y `Embarked`) en representaciones numÃ©ricas mediante tÃ©cnicas como _One-Hot Encoding_, permitiendo que el modelo las procese correctamente.
    

#### 2.4 Machine Learning

- **Concepto:** En esta fase se seleccionan, entrenan y evalÃºan diferentes algoritmos. Los datos se dividen en conjuntos de **entrenamiento** (para enseÃ±ar al modelo) y de **prueba** (para medir su rendimiento en datos no vistos). Este enfoque es clave para construir un modelo que generalice bien y evite el sobreajuste (overfitting).
    
- **AplicaciÃ³n en el proyecto (`4_machine_learning.ipynb`):** Se entrenÃ³ un modelo de clasificaciÃ³n (Random Forest) para predecir la supervivencia y se evaluÃ³ su precisiÃ³n y otras mÃ©tricas de rendimiento.
    

#### 2.5 Puesta en ProducciÃ³n

- **Concepto:** Se refiere al proceso de desplegar un modelo entrenado en un entorno real donde pueda recibir nuevos datos de entrada y devolver predicciones de forma automÃ¡tica. Esto permite que el modelo aporte valor al ser utilizado por aplicaciones, usuarios finales u otros sistemas.
    
- **AplicaciÃ³n en el proyecto (`app.py`):** Se desarrollÃ³ una aplicaciÃ³n web simple utilizando **Flask** que carga el modelo entrenado y permite a un usuario introducir las caracterÃ­sticas de un pasajero para obtener una predicciÃ³n de supervivencia en tiempo real.
    

#### 2.6 Pipelines

- **Concepto:** Un pipeline en Machine Learning es una herramienta que permite automatizar y encapsular todo el flujo de trabajo. Encadena mÃºltiples pasos (como el preprocesamiento de datos y el entrenamiento del modelo) en un Ãºnico objeto, asegurando consistencia y reproducibilidad.
    
- **AplicaciÃ³n en el proyecto (`5_pipeline.ipynb`, `pipeline.pkl`):** Se construyÃ³ un pipeline para consolidar todos los pasos de transformaciÃ³n de datos y el estimador final. Esto simplifica enormemente el proceso de hacer predicciones en producciÃ³n.
    

#### 2.7 Entrega

- **Concepto:** Es la culminaciÃ³n del proyecto, donde se presenta una soluciÃ³n funcional junto con toda la documentaciÃ³n, cÃ³digo y resultados. Una buena entrega demuestra que se han cumplido los objetivos planteados y que la soluciÃ³n es robusta y utilizable.
    
- **AplicaciÃ³n en el proyecto:** Este repositorio de GitHub, con sus notebooks, cÃ³digo de la aplicaciÃ³n, modelos guardados y este `README.md`, constituye la entrega final del proyecto.
    

### ðŸ“‚ Estructura del Repositorio

- `data/`: Contiene los conjuntos de datos originales, limpios y procesados.
    
- `1_clean.ipynb` a `5_pipeline.ipynb`: Jupyter Notebooks que detallan cada paso del proceso de Machine Learning.
    
- `app.py`: AplicaciÃ³n web desarrollada con Flask para interactuar con el modelo.
    
- `*.pkl`: Archivos serializados que contienen el pipeline y el modelo entrenado.
    
- `requirements.txt`: Lista de dependencias de Python necesarias para ejecutar el proyecto.
    

### âš™ï¸ Â¿CÃ³mo ejecutar el proyecto?

1. **Clonar el repositorio:**
    
    ```bash
    git clone [https://github.com/jesusvasquezjr3/Aprendizaje-Supervisado](https://github.com/jesusvasquezjr3/Aprendizaje-Supervisado)
    cd Aprendizaje-Supervisado
    ```
    
2. **Crear un entorno virtual e instalar dependencias:**
    
    ```bash
    python -m venv venv
    source venv/bin/activate  # En Windows: venv\Scripts\activate
    pip install -r requirements.txt
    ```
    
3. **Ejecutar la aplicaciÃ³n web:**
    
    ```bash
    python app.py
    ```
    
    Abre tu navegador y ve a `http://127.0.0.1:5000` para ver la aplicaciÃ³n en funcionamiento.
    
4. **Ingresar datos de prueba:**

    Usa la opciÃ³n a tu conveniencia, esto es para ingresar datos de prueba para probar el modelo, ingresalos abriendo una nueva terminal diferente a donde se estÃ¡ ejecutando **Flask**. 

    *Puedes sustituir los valores por los de tu preferencia para probar el modelo*

    - OpciÃ³n 1: Usar curl.exe directamente
    ```bash
    curl.exe -X POST http://127.0.0.1:5000/predecir -H "Content-Type: application/json" -d '{"input": [0,0,0,0,0,0,0]}'
    ```

    - OpciÃ³n 2: Usar Invoke-WebRequest (sintaxis PowerShell)
    ```bash
    Invoke-WebRequest -Uri "http://127.0.0.1:5000/predecir" -Method POST -ContentType "application/json" -Body '{"input": [0,0,0,0,0,0,0]}'
    ```

    - OpciÃ³n 3: Usar Invoke-RestMethod (mÃ¡s simple para APIs)
    ```bash
    Invoke-RestMethod -Uri "http://127.0.0.1:5000/predecir" -Method POST -ContentType "application/json" -Body '{"input": [0,0,0,0,0,0,0]}'
    ```



>[!Tip]
> **ðŸ“¥ Estructura del JSON de Entrada para Predicciones**
>
> Para realizar una predicciÃ³n a travÃ©s de la API, se debe enviar una solicitud `POST` al endpoint `/predict` con un JSON que contenga los datos del pasajero.
>
> El JSON debe ser un diccionario donde las claves son los nombres de las caracterÃ­sticas (`features`) y los valores son **listas** que contienen los datos de cada pasajero. Esta estructura permite realizar predicciones para uno o varios pasajeros a la vez.
>
> **Ejemplo de JSON para un solo pasajero:**
>
>```json
> {
>    "Pclass": [3],
>    "Sex": ["male"],
>    "Age": [25],
>    "SibSp": [1],
>    "Parch": [0],
>    "Fare": [7.5],
>    "Embarked": ["S"]
> }
>```
>
> **DescripciÃ³n de las claves:**
>
>- `Pclass`: Clase del ticket (1, 2, o 3).
>    
>- `Sex`: GÃ©nero (`male` o `female`).
>    
>- `Age`: Edad en aÃ±os (numÃ©rico).
>    
>- `SibSp`: NÃºmero de hermanos o cÃ³nyuges a bordo (numÃ©rico).
>    
>- `Parch`: NÃºmero de padres o hijos a bordo (numÃ©rico).
>    
>- `Fare`: Tarifa del pasaje (numÃ©rico).
>    
>- `Embarked`: Puerto de embarque (`C` = Cherbourg, `Q` = Queenstown, `S` = Southampton).

> ### Â¿CÃ³mo hacer las modificaciones al `input`?
> **Supongamos que quieres predecir la supervivencia de un hombre de 30 aÃ±os, que viaja en 3ra clase, solo, pagÃ³ una tarifa de 8.05 y embarcÃ³ en Southampton (S).**
> El comando `curl` se verÃ­a asÃ­:
> ```bash
> curl.exe -X POST http://127.0.0.1:5000/predecir -H "Content-Type: application/json" -d '{"Pclass": [3], "Sex": ["male"], "Age": [30], "SibSp": [0], "Parch": [0], "Fare": [8.05], "Embarked": ["S"]}'
> ```
