{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "596dc548",
   "metadata": {},
   "source": [
    "# üìö 2.4 Machine Learning\n",
    "\n",
    ">**Machine Learning (Aprendizaje Autom√°tico)** es una subdisciplina de la inteligencia artificial que permite a las computadoras aprender de forma autom√°tica a partir de datos, sin ser programadas expl√≠citamente para realizar una tarea espec√≠fica. En lugar de seguir instrucciones r√≠gidas, los algoritmos de machine learning identifican patrones, relaciones y estructuras en los datos mediante t√©cnicas estad√≠sticas y matem√°ticas, y utilizan ese conocimiento adquirido para hacer predicciones, clasificaciones o decisiones sobre nuevos datos. Este proceso implica un ciclo iterativo de entrenamiento, evaluaci√≥n y ajuste del modelo, con el objetivo de mejorar su rendimiento con la experiencia. El machine learning se aplica en una amplia gama de dominios ‚Äîdesde reconocimiento de voz y visi√≥n por computadora hasta recomendaciones personalizadas y diagn√≥stico m√©dico‚Äî y se divide en tres paradigmas principales: aprendizaje supervisado (con etiquetas), no supervisado (sin etiquetas) y por refuerzo (mediante recompensas y acciones). Su poder radica en su capacidad para generalizar a partir de ejemplos y adaptarse a entornos cambiantes, convirti√©ndolo en una herramienta fundamental en la era del big data y la automatizaci√≥n inteligente.\n",
    "\n",
    "## Importar paquetes\n",
    "Estamos en un nuevo notebook, entonces tenemos que volver a importar los paquetes que usaremos:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a86e73fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Pipeline\n",
    "from sklearn.pipeline import Pipeline\n",
    "\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "\n",
    "# M√©tricas de evaluaci√≥n\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Para guardar el modelo\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd74b1d4",
   "metadata": {},
   "source": [
    "## Carga de datos\n",
    "En el notebook anterior guardamos nuestros datos procesados en el directorio `data/`. Carguemos estos datos a DataFrames."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "64078516",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/titanic_procesado.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "04af69df",
   "metadata": {},
   "source": [
    "## Divisi√≥n de datos\n",
    "Recordemos que estamos por implementar algoritmos de aprendizaje supervisado. Esto implica que necesitamos dividir nuestros datos en dos conjuntos: uno para entrenamiento y otro para pruebas. El conjunto de entrenamiento se utiliza para ajustar el modelo, mientras que el conjunto de pruebas se usa para evaluar su rendimiento y asegurarnos de que generaliza bien a datos no vistos. Esta divisi√≥n, conocida como divisi√≥n **entrenamiento-prueba**.\n",
    "\n",
    "El conjunto de entrenamiento se usar√° en el proceso de entrenamiento para que nuestro modelo pueda ‚Äúaprenderse‚Äù las respuestas correctas a las predicciones que queremos realizar.\n",
    "\n",
    "### `train_test_split`\n",
    "\n",
    "Utilizaremos la funci√≥n `train_test_split` de Sckit Learn para realizar esta divisi√≥n.\n",
    "\n",
    "Primero que nada, crearemos un DataFrame que contenga los datos sin la variable objetivo (target) Survived, y el otro contendr√° √∫nicamente esta variable objetivo Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "6c127433",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.433152</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.368146</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.579431</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.615097</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.462346</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.438286</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.563806</td>\n",
       "      <td>0.125</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.595112</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.563806</td>\n",
       "      <td>0.000</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.448347</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Pclass  Sex       Age  SibSp  Parch      Fare  Embarked\n",
       "0     1.0  1.0  0.433152  0.125    0.0  0.368146       1.0\n",
       "1     0.0  0.0  0.579431  0.125    0.0  0.615097       0.0\n",
       "2     1.0  0.0  0.462346  0.000    0.0  0.438286       1.0\n",
       "3     0.0  0.0  0.563806  0.125    0.0  0.595112       1.0\n",
       "4     1.0  1.0  0.563806  0.000    0.0  0.448347       1.0"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = df.drop(['Survived'], axis=1)\n",
    "y = df['Survived']\n",
    "X.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1157e62d",
   "metadata": {},
   "source": [
    "Notamos que nuestra X ya no contiene Survived."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "69ec8411",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    0\n",
       "1    1\n",
       "2    1\n",
       "3    1\n",
       "4    0\n",
       "Name: Survived, dtype: int64"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d8afba2",
   "metadata": {},
   "source": [
    "\n",
    "---\n",
    "\n",
    "Hagamos la divisi√≥n entrenamiento-prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9ec6d6fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.2, random_state = 42)\n",
    "X_train = X_train.values  # Convertir a NumPy array\n",
    "y_train = y_train.values  # Convertir a NumPy array\n",
    "X_test = X_test.values    # Convertir a NumPy array\n",
    "y_test = y_test.values    # Convertir a NumPy array"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "684e59b6",
   "metadata": {},
   "source": [
    "¬øPara qu√© sirven los par√°metros `test_size` y `random_state` en `train_test_split`?\n",
    "\n",
    "**test_size = 0.2**\n",
    "- **Prop√≥sito:** Define qu√© porcentaje de los datos se destinar√° al conjunto de **prueba (test)**\n",
    "- **Valor 0.2:** Significa que el 20% de los datos ser√° para testing y el 80% restante para entrenamiento\n",
    "- **Ejemplos de valores:**\n",
    "  - `test_size = 0.2` ‚Üí 80% entrenamiento, 20% prueba\n",
    "  - `test_size = 0.3` ‚Üí 70% entrenamiento, 30% prueba  \n",
    "  - `test_size = 100` ‚Üí 100 registros para prueba (n√∫mero absoluto)\n",
    "\n",
    "**random_state = 42**\n",
    "- **Prop√≥sito:** Controla la **reproducibilidad** de la divisi√≥n aleatoria\n",
    "- **Valor 42:** Es una \"semilla\" que asegura que la divisi√≥n sea siempre la misma\n",
    "- **Importancia:** Sin este par√°metro, cada vez que ejecutes el c√≥digo obtendr√≠as una divisi√≥n diferente de los datos\n",
    "\n",
    "**Ejemplo pr√°ctico:**\n",
    "```python\n",
    "# Sin random_state - resultados diferentes cada vez\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2)\n",
    "\n",
    "# Con random_state - mismos resultados siempre\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "```\n",
    "\n",
    "**¬øPor qu√© es importante?**\n",
    "- **test_size:** Asegura una evaluaci√≥n justa del modelo con datos no vistos\n",
    "- **random_state:** Permite que tus experimentos sean reproducibles y comparables\n",
    "\n",
    ">**Nota:** El n√∫mero 42 es solo una convenci√≥n popular (referencia a \"Gu√≠a del Autoestopista Gal√°ctico\"), puedes usar cualquier n√∫mero entero.\n",
    "\n",
    "## Selecci√≥n de modelo\n",
    "Como pudiste notar, importamos una gran cantidad de modelos de Scikit Learn:\n",
    "\n",
    "```python\n",
    "# Modelos\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier, AdaBoostClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from lightgbm import LGBMClassifier\n",
    "from sklearn.naive_bayes import GaussianNB, BernoulliNB\n",
    "```\n",
    "\n",
    "√âsta es una de las grandes ventajas de implementar aprendizaje autom√°tico con herramientas modernas como Python y Scikit Learn. El c√≥digo que implementaremos nos permitir√° probr todos estos modelos. Eligiremos el mejor modelo no a partir de nuestra intuici√≥n, sino con base en las m√©tricas de precisi√≥n que resulte de cada uno en su fase de entrenamiento.\n",
    "\n",
    "### GridSearch\n",
    "Implementaremos una t√©cnica llamada GridSearch, la cual nos permite encontrar los mejores hiperpar√°metros para nuestro modelo de aprendizaje autom√°tico. GridSearch explora exhaustivamente un conjunto predefinido de valores para cada hiperpar√°metro, entrenando y evaluando el modelo con cada combinaci√≥n posible. Al final, selecciona la combinaci√≥n que proporciona el mejor rendimiento seg√∫n una m√©trica de evaluaci√≥n espec√≠fica, garantizando as√≠ que el modelo est√© optimizado para obtener los mejores resultados posibles.\n",
    "\n",
    "El primer paso para implementar GridSearch es crear un diccionario que contenga todos los modelos que queremos probar y los hiperpar√°metros que queramos probar en cada uno de estos. \n",
    "\n",
    "```python\n",
    "modelos = {\n",
    "    'Logistic Regression': {\n",
    "        'model': LogisticRegression(),\n",
    "        'params': {\n",
    "            'model__C': [0.1],\n",
    "            'model__max_iter': [1000]\n",
    "        }\n",
    "    },\n",
    "    'Support Vector Classifier': {\n",
    "        'model': SVC(),\n",
    "        'params': {\n",
    "            'model__kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'model__C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'Decision Tree Classifier': {\n",
    "        'model': DecisionTreeClassifier(),\n",
    "        'params': {\n",
    "            'model__splitter': ['best', 'random'],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Random Forest Classifier': {\n",
    "        'model': RandomForestClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4],\n",
    "            'model__max_features': ['auto', 'sqrt', 'log2']\n",
    "        }\n",
    "    },\n",
    "    'Gradient Boosting Classifier': {\n",
    "        'model': GradientBoostingClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'AdaBoost Classifier': {\n",
    "        'model': AdaBoostClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100]\n",
    "        }\n",
    "    },\n",
    "    'K-Nearest Neighbors Classifier': {\n",
    "        'model': KNeighborsClassifier(),\n",
    "        'params': {\n",
    "            'model__n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'XGBoost Classifier': {\n",
    "        'model': XGBClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3]\n",
    "        }\n",
    "    },\n",
    "    'LGBM Classifier': {\n",
    "        'model': LGBMClassifier(),\n",
    "        'params': {\n",
    "            'model__n_estimators': [10, 100],\n",
    "            'model__max_depth': [None, 1, 2, 3],\n",
    "            'model__learning_rate': [0.1, 0.2, 0.3],\n",
    "            'model__verbose': [-1]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'model': GaussianNB(),\n",
    "        'params': {}\n",
    "    },\n",
    "    'Naive Bayes Classifier': {\n",
    "        'model': BernoulliNB(),\n",
    "        'params': {\n",
    "            'model__alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "> Realiza una r√°pida investigaci√≥n de algunos de estos modelos. Describe sus particularidades y los hiperpar√°metros que requiere cada uno de ellos.\n",
    "\n",
    "## Entrenamiento\n",
    "Ejecutemos el c√≥digo completo que realizar√° el ajuste de cada uno de los modelos. Ejec√∫talo en tu notebook, y posteriormente analizaremos l√≠nea por l√≠nea."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "22214342",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Rendimiento de los modelos de clasificaci√≥n\n",
      "                                 Modelo  Precisi√≥n\n",
      "4     Clasificador de Gradient Boosting       0.83\n",
      "6      Clasificador K-Nearest Neighbors       0.83\n",
      "7                  Clasificador XGBoost       0.82\n",
      "8                     Clasificador LGBM       0.81\n",
      "3    Clasificador de Bosques Aleatorios       0.80\n",
      "1   Clasificador de Vectores de Soporte       0.80\n",
      "2     Clasificador de √Årbol de Decisi√≥n       0.80\n",
      "0                   Regresi√≥n Log√≠stica       0.79\n",
      "5                 Clasificador AdaBoost       0.79\n",
      "10             Clasificador Naive Bayes       0.79\n",
      "9                            GaussianNB       0.76\n",
      "---------------------------------------------------\n",
      "MEJOR MODELO DE CLASIFICACI√ìN\n",
      "Modelo: Clasificador de Gradient Boosting\n",
      "Precisi√≥n: 0.83\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mel_f\\Music\\Aprendizaje Supervisado Hybridge\\Aprendizaje-Supervisado\\nombre_proyecto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Definir los modelos y sus respectivos hiperpar√°metros para GridSearch\n",
    "modelos = {\n",
    "    'Regresi√≥n Log√≠stica': {\n",
    "        'modelo': LogisticRegression(),\n",
    "        'parametros': {\n",
    "            'C': [0.01, 0.1, 1, 10, 100],\n",
    "            'penalty': ['l1', 'l2'],\n",
    "            'solver': ['liblinear', 'saga'],\n",
    "            'max_iter': [100, 500, 1000]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Vectores de Soporte': {\n",
    "        'modelo': SVC(),\n",
    "        'parametros': {\n",
    "            'kernel': ['linear', 'poly', 'rbf', 'sigmoid'],\n",
    "            'C': [0.1, 1, 10]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de √Årbol de Decisi√≥n': {\n",
    "        'modelo': DecisionTreeClassifier(),\n",
    "        'parametros': {\n",
    "            'splitter': ['best', 'random'],\n",
    "            'max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Bosques Aleatorios': {\n",
    "        'modelo': RandomForestClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3, 4],\n",
    "            'max_features': ['sqrt', 'log2', None]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador de Gradient Boosting': {\n",
    "        'modelo': GradientBoostingClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3, 4]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador AdaBoost': {\n",
    "        'modelo': AdaBoostClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador K-Nearest Neighbors': {\n",
    "        'modelo': KNeighborsClassifier(),\n",
    "        'parametros': {\n",
    "            'n_neighbors': [3, 5, 7]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador XGBoost': {\n",
    "        'modelo': XGBClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3]\n",
    "        }\n",
    "    },\n",
    "    'Clasificador LGBM': {\n",
    "        'modelo': LGBMClassifier(),\n",
    "        'parametros': {\n",
    "            'n_estimators': [10, 100],\n",
    "            'max_depth': [None, 1, 2, 3],\n",
    "            'learning_rate': [0.1, 0.2, 0.3],\n",
    "            'verbose': [-1]\n",
    "        }\n",
    "    },\n",
    "    'GaussianNB': {\n",
    "        'modelo': GaussianNB(),\n",
    "        'parametros': {}\n",
    "    },\n",
    "    'Clasificador Naive Bayes': {\n",
    "        'modelo': BernoulliNB(),\n",
    "        'parametros': {\n",
    "            'alpha': [0.1, 1.0, 10.0]\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "# Inicializar variables para almacenar los puntajes de los modelos y el mejor estimador\n",
    "puntajes_modelos = []\n",
    "mejor_precision = 0\n",
    "mejor_estimador = None\n",
    "mejor_modelo = None\n",
    "estimadores = {}\n",
    "\n",
    "# Iterar sobre cada modelo y sus hiperpar√°metros\n",
    "for nombre, info_modelo in modelos.items():\n",
    "    # Inicializar GridSearchCV con el modelo y los hiperpar√°metros\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=info_modelo['modelo'],\n",
    "        param_grid=info_modelo['parametros'],\n",
    "        cv=5,\n",
    "        scoring='accuracy',\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Ajustar GridSearchCV con los datos de entrenamiento\n",
    "    grid_search.fit(X_train, y_train)\n",
    "    \n",
    "    # Hacer predicciones con el modelo ajustado\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "    \n",
    "    # Calcular la precisi√≥n de las predicciones\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "    \n",
    "    # Almacenar los resultados del modelo\n",
    "    puntajes_modelos.append({\n",
    "        'Modelo': nombre,\n",
    "        'Precisi√≥n': precision\n",
    "    })\n",
    "\n",
    "    estimadores[nombre] = grid_search.best_estimator_\n",
    "    \n",
    "    # Actualizar el mejor modelo si la precisi√≥n actual es mayor que la mejor precisi√≥n encontrada\n",
    "    if precision > mejor_precision:\n",
    "        mejor_modelo = nombre\n",
    "        mejor_precision = precision\n",
    "        mejor_estimador = grid_search.best_estimator_\n",
    "\n",
    "# Convertir los resultados a un DataFrame para una mejor visualizaci√≥n\n",
    "metricas = pd.DataFrame(puntajes_modelos).sort_values('Precisi√≥n', ascending=False)\n",
    "\n",
    "# Imprimir el rendimiento de los modelos de clasificaci√≥n\n",
    "print(\"Rendimiento de los modelos de clasificaci√≥n\")\n",
    "print(metricas.round(2))\n",
    "\n",
    "# Imprimir el mejor modelo y su precisi√≥n\n",
    "print('---------------------------------------------------')\n",
    "print(\"MEJOR MODELO DE CLASIFICACI√ìN\")\n",
    "print(f\"Modelo: {mejor_modelo}\")\n",
    "print(f\"Precisi√≥n: {mejor_precision:.2f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70ad340a",
   "metadata": {},
   "source": [
    "> No te preocupes si ves algunos warnings en el output. Las advertencias no interfieren con el proceso de entrenamiento.\n",
    "\n",
    "**Investiga qu√© representa la m√©trica de precisi√≥n.**\n",
    "La **precisi√≥n** (en ingl√©s, *precision*) es una m√©trica de evaluaci√≥n utilizada en problemas de clasificaci√≥n que mide la proporci√≥n de predicciones positivas correctas entre todas las predicciones que el modelo ha etiquetado como positivas. En t√©rminos formales, se calcula como el cociente entre el n√∫mero de **verdaderos positivos (TP)** y la suma de verdaderos positivos m√°s **falsos positivos (FP)**:  \n",
    "\\[\n",
    "\\text{Precisi√≥n} = \\frac{TP}{TP + FP}\n",
    "\\]  \n",
    "Esta m√©trica responde a la pregunta: *\"De todas las veces que el modelo dijo 's√≠' (positivo), ¬øcu√°ntas veces estaba realmente en lo correcto?\"*. Es especialmente √∫til cuando el costo de un falso positivo es alto, como en sistemas de detecci√≥n de enfermedades o fraudes, donde no queremos alertar falsamente. A diferencia del accuracy (exactitud), la precisi√≥n ignora los verdaderos negativos, por lo que es m√°s sensible al desequilibrio de clases y al rendimiento en la clase positiva. Por ejemplo, si un modelo tiene una precisi√≥n de 0.83, significa que del 83% de las veces que predijo \"positivo\", fue correcto. \n",
    "\n",
    "---\n",
    "\n",
    "Aunque no lo creas, aqu√≠ termina la fase de entrenamiento. Hemos ajustado 11 modelos diferentes, cada uno con diferentes hiperpar√°metros, y ahora podemos seleccionar aqu√©l que haya logrado obtener una mayor precisi√≥n.\n",
    "\n",
    "Las √∫ltimas l√≠neas del c√≥digo anterior sirven precisamente para mostrarnos, en un formato muy amigable, el resultado de cada uno de los modelos. Podemos ver que el modelo que alcanz√≥ la precisi√≥n m√°s alta es el **Clasificador de Gradient Boosting**.\n",
    "\n",
    ">Es posible que en tu computadora obtengas otro resultado, sin embargo, lo m√°s probable es que la precisi√≥n sea similar a 0.83.\n",
    "\n",
    "**¬øy ahora qu√©?**\n",
    "\n",
    "Ya que seleccionamos nuestro modelo, podemos comenzar a hacer inferencia. Antes de pasar a este punto, analicemos una por una las l√≠neas de c√≥digo de entrenamiento.\n",
    "\n",
    "## Revisi√≥n de c√≥digo\n",
    "\n",
    "Lo primero que tenemos es el diccionario de modelos. Cada elemento de este diccionario representa un modelo y los diferentes hiperpar√°metros que probaremos. \n",
    "\n",
    "Hemos repetido esta palabra varias veces, pero no nos hemos detenido a revisar qu√© es. \n",
    "\n",
    "Pregunta a la IA de tu preferencia:\n",
    "\n",
    "Prompt üí°:\n",
    "> Explica con detalle qu√© son los hiperpar√©metros en el contexto del aprendizaje autom√°tico."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2b85ecc9",
   "metadata": {},
   "source": [
    ">**Los hiperpar√°metros son como los settings ‚öôÔ∏è que podemos configurar al momento de entrenar un modelo.**\n",
    "\n",
    "## Sin GridSearch\n",
    "Para comprender la b√∫squeda en cuadr√≠cula (Grid Search) m√°s f√°cilmente, primero veamos c√≥mo se entrena un modelo individualmente. \n",
    "\n",
    "Entrenemos una regresi√≥n log√≠stica:\n",
    "```python\n",
    "# Esto ya lo tenemos importado. Lo ponemos nuevamente nada m√°s de referencia\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "# Creamos el modelo de regresi√≥n log√≠stica\n",
    "model = LogisticRegression()\n",
    "\n",
    "# Entrenamos el modelo con los datos de entrenamiento\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizamos predicciones con el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluamos el modelo usando precisi√≥n\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisi√≥n del modelo: {accuracy:.2f}\")\n",
    "```\n",
    "**Output**\n",
    "```bash\n",
    "Precisi√≥n del modelo: 0.80\n",
    "```\n",
    "\n",
    "**¬øY los hiperpar√°metros?** Si no especificamos hiperpar√°metros, se utilizar√°n los valores por defecto que define Scikit Learn para su modelo LogisticRegression\n",
    "\n",
    "**¬øC√≥mo sabemos qu√© hiperpar√°metros podemos usar?**\n",
    "Esto lo podemos consultar en la documentaci√≥n del modelo en cuesti√≥n. Googlea scikit learn logistic regression. El primer link (o uno de los primeros) que aparece nos lleva la documentaci√≥n oficial de la regresi√≥n log√≠stica de Scikit Learn: https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LogisticRegression.html\n",
    "\n",
    "O bien, podemos preguntarle a GhatGPT o cualquier otra IA:\n",
    "\n",
    "Prompt üí°:\n",
    "> ¬øCu√°les son los hiperpar√°metros m√°s comunes que podemos utilizar en una regresi√≥n log√≠stica de Scikit Learn?\n",
    "\n",
    "Respuesta ü§ñ:\n",
    "> **C**: Controla la regularizaci√≥n del modelo. Un valor m√°s bajo implica una regularizaci√≥n m√°s fuerte (mayor penalizaci√≥n por pesos grandes), mientras que un valor m√°s alto implica una regularizaci√≥n m√°s d√©bil. Por defecto es 1.0.\n",
    ">\n",
    "> **penalty**: Especifica el tipo de penalizaci√≥n para la regularizaci√≥n. Los valores posibles son 'l1', 'l2', 'elasticnet', o None. 'l2' es el valor por defecto.\n",
    ">\n",
    "> **solver**: El algoritmo utilizado para optimizar la funci√≥n de coste. Los valores posibles incluyen 'newton-cg', 'lbfgs', 'liblinear', 'saga', y 'adam'. 'lbfgs' es el valor por defecto.\n",
    ">\n",
    "> **max_iter**: El n√∫mero m√°ximo de iteraciones para el algoritmo de optimizaci√≥n. El valor por defecto es 100.\n",
    ">\n",
    "> **class_weight**: Permite ajustar el peso de las clases en el entrenamiento. Puede ser None, 'balanced', o un diccionario con pesos espec√≠ficos. Por defecto es None.\n",
    ">\n",
    "> **multi_class**: Define el tipo de problema de clasificaci√≥n m√∫ltiple. Los valores posibles son 'ovr' (one-vs-rest) y 'multinomial'. 'ovr' es el valor por defecto.\n",
    ">\n",
    "> **fit_intercept**: Indica si se debe ajustar el intercepto. El valor por defecto es True.\n",
    ">\n",
    "> **warm_start**: Permite reutilizar la soluci√≥n de la llamada anterior para iniciar el siguiente ajuste. El valor por defecto es False.\n",
    ">\n",
    "> **tol**: El umbral de tolerancia para el criterio de convergencia. El valor por defecto es 1e-4\n",
    "\n",
    "Entonces podemos implementar nuestra regresi√≥n log√≠stica especificando algunos hiperpar√°metros:\n",
    "```python\n",
    "model = LogisticRegression(\n",
    "    C=0.5,                  # Valor de regularizaci√≥n\n",
    "    penalty='l2',            # Tipo de penalizaci√≥n (l2 es la regularizaci√≥n Ridge)\n",
    "    solver='lbfgs',         # Algoritmo de optimizaci√≥n\n",
    "    max_iter=200,           # N√∫mero m√°ximo de iteraciones\n",
    "    class_weight='balanced' # Ajustar pesos de las clases\n",
    ")\n",
    "\n",
    "# Entrenar el modelo\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Realizar predicciones en el conjunto de prueba\n",
    "y_pred = model.predict(X_test)\n",
    "\n",
    "# Evaluar la precisi√≥n del modelo\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "\n",
    "print(f\"Precisi√≥n del modelo: {accuracy:.2f}\")\n",
    "```\n",
    "**Output:**\n",
    "```bash\n",
    "Precisi√≥n del modelo: 0.78\n",
    "```\n",
    "(Empeor√≥ üòÖüòÖüòÖ)\n",
    "\n",
    "Cuando vemos la lista larga de hiperpar√°metros, y todos los posibles valores que podemos dar a cada uno de ellos, sin duda nos sentimos algo abrumados. Despu√©s de todo, ¬øc√≥mo vamos a aprendernos todas estas combinaciones?\n",
    "\n",
    "> **¬°√âste es precisamente el problema que GridSearch busca resolver!**\n",
    "\n",
    "En lugar de probar combinaciones de hiperpar√°metros uno por uno, implementamos un GridSearch que probar√° todas las diferentes combinaciones de hiperpar√°metros que espefiquemos.\n",
    "\n",
    "Veamos nuevamente el objeto de regresi√≥n log√≠stica en el diccionario de modelos:\n",
    "```python\n",
    "'Regresi√≥n Log√≠stica': {\n",
    "    'modelo': LogisticRegression(),\n",
    "    'parametros': {\n",
    "        'C': [0.1],\n",
    "        'max_iter': [1000]\n",
    "    }\n",
    "},\n",
    "```\n",
    "Podemos ver que aqu√≠ no estamos probando diferentes valores de `C` o `max_iter`. Cambiemos esto:\n",
    "```python\n",
    "'Regresi√≥n Log√≠stica': {\n",
    "    'modelo': LogisticRegression(),\n",
    "    'parametros': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [100, 500, 1000]\n",
    "    }\n",
    "}\n",
    "```\n",
    "\n",
    "Ahora al momento de ejecutar la b√∫squeda en cuadr√≠cula, probaremos muchas m√°s combinaciones de hiperpar√°metros para la regresi√≥n log√≠stica. Claro, esto implica que el proceso de entrenamiento tardar√° un poco m√°s. \n",
    "\n",
    "### Con GridSearch\n",
    "Lo que hace GridSearch por detr√°s de las cortinas es construir un modelo por cada posible combinaci√≥n de hiperpar√°metros. Si creamos el objeto de la siguiente manera:\n",
    "```python\n",
    "'Regresi√≥n Log√≠stica': {\n",
    "    'modelo': LogisticRegression(),\n",
    "    'parametros': {\n",
    "        'C': [0.01, 0.1, 1, 10, 100],\n",
    "        'penalty': ['l1', 'l2'],\n",
    "        'solver': ['liblinear', 'saga'],\n",
    "        'max_iter': [100, 500, 1000]\n",
    "    }\n",
    "}\n",
    "```\n",
    "literalmente se construir√°n todos estos objetos:\n",
    "```bash\n",
    "LogisticRegression(C=0.01, penalty=\"l1\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=0.01, penalty=\"l1\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=0.01, penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=0.01, penalty=\"l2\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=0.01, penalty=\"l2\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=0.01, penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=0.01, penalty=\"l2\", solver=\"saga\", max_iter=100)\n",
    "LogisticRegression(C=0.01, penalty=\"l2\", solver=\"saga\", max_iter=500)\n",
    "LogisticRegression(C=0.01, penalty=\"l2\", solver=\"saga\", max_iter=1000)\n",
    "\n",
    "LogisticRegression(C=0.1, penalty=\"l1\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=0.1, penalty=\"l1\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=0.1, penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=0.1, penalty=\"l2\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=0.1, penalty=\"l2\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=0.1, penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=0.1, penalty=\"l2\", solver=\"saga\", max_iter=100)\n",
    "LogisticRegression(C=0.1, penalty=\"l2\", solver=\"saga\", max_iter=500)\n",
    "LogisticRegression(C=0.1, penalty=\"l2\", solver=\"saga\", max_iter=1000)\n",
    "\n",
    "LogisticRegression(C=1, penalty=\"l1\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=1, penalty=\"l1\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=1, penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=1, penalty=\"l2\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=1, penalty=\"l2\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=1, penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=1, penalty=\"l2\", solver=\"saga\", max_iter=100)\n",
    "LogisticRegression(C=1, penalty=\"l2\", solver=\"saga\", max_iter=500)\n",
    "LogisticRegression(C=1, penalty=\"l2\", solver=\"saga\", max_iter=1000)\n",
    "\n",
    "LogisticRegression(C=10, penalty=\"l1\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=10, penalty=\"l1\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=10, penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=10, penalty=\"l2\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=10, penalty=\"l2\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=10, penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=10, penalty=\"l2\", solver=\"saga\", max_iter=100)\n",
    "LogisticRegression(C=10, penalty=\"l2\", solver=\"saga\", max_iter=500)\n",
    "LogisticRegression(C=10, penalty=\"l2\", solver=\"saga\", max_iter=1000)\n",
    "\n",
    "LogisticRegression(C=100, penalty=\"l1\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=100, penalty=\"l1\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=100, penalty=\"l1\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=100, penalty=\"l2\", solver=\"liblinear\", max_iter=100)\n",
    "LogisticRegression(C=100, penalty=\"l2\", solver=\"liblinear\", max_iter=500)\n",
    "LogisticRegression(C=100, penalty=\"l2\", solver=\"liblinear\", max_iter=1000)\n",
    "LogisticRegression(C=100, penalty=\"l2\", solver=\"saga\", max_iter=100)\n",
    "LogisticRegression(C=100, penalty=\"l2\", solver=\"saga\", max_iter=500)\n",
    "LogisticRegression(C=100, penalty=\"l2\", solver=\"saga\", max_iter=1000)\n",
    "```\n",
    "\n",
    "---\n",
    "\n",
    "Esto realmente representa la ventaja o el avance de machine learning. La regresi√≥n log√≠stica se empez√≥ a utilizar en el siglo pasado, por lo que no es una t√©cnica nueva.\n",
    "\n",
    "Sin embargo, lo que s√≠ es nuevo (adem√°s del poder computacional que ahora tenemos disponible) es la capacidad de contar con herramientas avanzadas como las que estamos implementando. Estas herramientas nos permiten probar hip√≥tesis y experimentar con modelos de manera mucho m√°s r√°pida y eficiente.\n",
    "\n",
    "### Variables auxiliares\n",
    "Despu√©s de definir el diccionario de modelos e hiperpar√°metros, creamos unas variables auxiliares que nos servir√°n para mostrar f√°cilmente el mejor modelo que resulte de la b√∫squeda en cuadr√≠cula:\n",
    "```python\n",
    "# Inicializar variables para almacenar los puntajes de los modelos y el mejor estimador\n",
    "puntajes_modelos = []\n",
    "mejor_precision = 0\n",
    "mejor_estimador = None\n",
    "mejor_modelo = None\n",
    "estimadores = {}\n",
    "```\n",
    "\n",
    "### Ajuste de modelos\n",
    "El proceso de ajuste lo haremos por cada uno de los elementos de nuestro diccionario de modelos. \n",
    "\n",
    "Utilizaremos nada m√°s y nada menos que un ciclo `for`.\n",
    "```python\n",
    "# Iterar sobre cada modelo y sus hiperpar√°metros\n",
    "for nombre, info_modelo in modelos.items():\n",
    "```\n",
    "Adentro de este ciclo `for` ajustaremos los modelos utilizando GridSearch\n",
    "```python\n",
    "grid_search = GridSearchCV(\n",
    "    estimator=info_modelo['modelo'],\n",
    "    param_grid=info_modelo['parametros'],\n",
    "    cv=5,\n",
    "    scoring='accuracy',\n",
    "    verbose=0,\n",
    "    n_jobs=-1,\n",
    ")\n",
    "```\n",
    "\n",
    ">Los par√°metros **`cv`**, **`verbose`** y **`n_jobs`** son configuraciones comunes en herramientas de validaci√≥n y optimizaci√≥n de modelos en librer√≠as como scikit-learn: **`cv`** define el n√∫mero de particiones (folds) para la validaci√≥n cruzada, permitiendo evaluar la estabilidad y generalizaci√≥n del modelo; **`verbose`** controla el nivel de detalle de la informaci√≥n que se imprime durante la ejecuci√≥n (√∫til para monitorear el progreso, especialmente en procesos largos); y **`n_jobs`** especifica el n√∫mero de n√∫cleos de CPU a utilizar en paralelo para acelerar el c√≥mputo ‚Äî usar `-1` aprovecha todos los n√∫cleos disponibles. Juntos, estos par√°metros permiten equilibrar eficiencia, transparencia y rigor estad√≠stico en el entrenamiento y ajuste de modelos.\n",
    "\n",
    "Una vez creado el objeto `grid_search`, procedemos a ajustar el modelo, y posteriormente haremos predicciones utilizando el conjunto `X_test`. Estos resultados los almacenaremos en la variable `y_pred`. \n",
    "\n",
    "Finalmente, para medir la presici√≥n del modelo que acabamos de ajustar, compararemos los valores de `y_pred` y `y_test` para ‚Äúver a cu√°ntos le atin√≥ el modelo‚Äù. \n",
    "\n",
    "Los resultados los iremos guardando en una lista llamada `puntajes_modelos`:\n",
    "```python\n",
    "# Ajustar GridSearchCV con los datos de entrenamiento\n",
    "grid_search.fit(X_train, y_train)\n",
    "\n",
    "# Hacer predicciones con el modelo ajustado\n",
    "y_pred = grid_search.predict(X_test)\n",
    "\n",
    "# Calcular la precisi√≥n de las predicciones\n",
    "precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "# Almacenar los resultados del modelo\n",
    "puntajes_modelos.append({\n",
    "    'Modelo': nombre,\n",
    "    'Precisi√≥n': precision\n",
    "})\n",
    "\n",
    "estimadores[nombre] = grid_search.best_estimator_\n",
    "```\n",
    "El siguiente bloque lo usaremos para ir guardando el mejor modelo y mejor precisi√≥n. De esta forma, cuando termine todo el ciclo de entrenamiento, podremos mostrar los resultados f√°cilmente:\n",
    "```python\n",
    "# Actualizar el mejor modelo si la precisi√≥n actual es mayor que la mejor precisi√≥n encontrada\n",
    "if precision > mejor_precision:\n",
    "    mejor_modelo = nombre\n",
    "    mejor_precision = precision\n",
    "    mejor_estimador = grid_search.best_estimator_\n",
    "```\n",
    "\n",
    "**¬°Listo!**\n",
    "\n",
    "Con esto termina el bloque de c√≥digo del `for`\n",
    "\n",
    "Ahora escribiremos c√≥digo para mostrar los resultados:\n",
    "```python\n",
    "# Convertir los resultados a un DataFrame para una mejor visualizaci√≥n\n",
    "metricas = pd.DataFrame(puntajes_modelos).sort_values('Precisi√≥n', ascending=False)\n",
    "\n",
    "# Imprimir el rendimiento de los modelos de clasificaci√≥n\n",
    "print(\"Rendimiento de los modelos de clasificaci√≥n\")\n",
    "print(metricas.round(2))\n",
    "\n",
    "# Imprimir el mejor modelo y su precisi√≥n\n",
    "print('---------------------------------------------------')\n",
    "print(\"MEJOR MODELO DE CLASIFICACI√ìN\")\n",
    "print(f\"Modelo: {mejor_modelo}\")\n",
    "print(f\"Precisi√≥n: {mejor_precision:.2f}\")\n",
    "```\n",
    "Esto nos mostrar√° el siguiente output:\n",
    "```bash\n",
    "> Rendimiento de los modelos de clasificaci√≥n\n",
    "                                 Modelo  Precisi√≥n\n",
    "4     Clasificador de Gradient Boosting       0.83\n",
    "6      Clasificador K-Nearest Neighbors       0.83\n",
    "7                  Clasificador XGBoost       0.82\n",
    "5                 Clasificador AdaBoost       0.81\n",
    "8                     Clasificador LGBM       0.81\n",
    "1   Clasificador de Vectores de Soporte       0.80\n",
    "2     Clasificador de √Årbol de Decisi√≥n       0.80\n",
    "3    Clasificador de Bosques Aleatorios       0.80\n",
    "0                   Regresi√≥n Log√≠stica       0.79\n",
    "10             Clasificador Naive Bayes       0.79\n",
    "9                            GaussianNB       0.76\n",
    "---------------------------------------------------\n",
    "MEJOR MODELO DE CLASIFICACI√ìN\n",
    "Modelo: Clasificador de Gradient Boosting\n",
    "Precisi√≥n: 0.83\n",
    "```\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "70f0f04f",
   "metadata": {},
   "source": [
    "> **¬øCu√°l es la diferencia entre las variables `mejor_estimador` y `mejor_modelo`?**\n",
    "> La diferencia es:\n",
    ">\n",
    "> - **mejor_modelo**: Es una variable tipo string que guarda el **nombre** del modelo que obtuvo la mayor precisi√≥n (por ejemplo, `\"Clasificador de Gradient Boosting\"`).\n",
    ">\n",
    "> - **mejor_estimador**: Es el **objeto del modelo entrenado** (el mejor estimador ajustado por GridSearchCV), es decir, la instancia del modelo con los hiperpar√°metros √≥ptimos encontrados, lista para hacer predicciones.\n",
    "\n",
    "### Inferencia\n",
    "Terminamos nuestro proceso de entrenamiento. Lo que viene ahora es algo que llamamos ‚Äúinferencia‚Äù. Esto significa que podremos usar nuestro modelo entrenado para predecir datos nuevos que no haya visto el modelo todav√≠a. \n",
    "\n",
    "En el contexto de nuestro proyecto, podr√≠amos ya usar nuestro modelo para alimentarle nueva informaci√≥n de pasajeros y predecir si sobrevivi√≥ o no. \n",
    "\n",
    "En nuestro proceso de entrenamiento, guardamos el mejor estimador en la variable mejor_estimador`. Si vemos el contenido de esta variable en Jupyter, veremos algo as√≠:\n",
    "\n",
    "```python\n",
    "mejor_estimador\n",
    "```\n",
    "\n",
    "Para predecir nuevos valores, usaremos el m√©todo predict , mismo que recibe un numpy array como argumento, y √©ste debe ser de exactamente las mismas dimensiones que X_train y X_test.\n",
    "\n",
    "Obtengamos los primeros datos de X_train y de y_train:\n",
    "```python\n",
    "X_train[0]\n",
    "```\n",
    "```bash\n",
    "> array([0.        , 1.        , 0.6159084 , 0.        , 0.        ,\n",
    "       0.55547282, 1.        ])\n",
    "```\n",
    "```python\n",
    "y_train[0]\n",
    "```\n",
    "```bash\n",
    "> np.int64(0) \n",
    "```\n",
    "Ahora creemos un nuevo numpy array con los datos que vemos en `X_train[0]`\n",
    "```python\n",
    "nuevos_datos = np.array([0,1,0.6159084,0,0,0.55547282,1]).reshape(1,-1)\n",
    "```\n",
    "Y finalmente corramos predict\n",
    "```python\n",
    "mejor_estimador.predict(nuevos_datos)\n",
    "```\n",
    "```bash\n",
    "> array([0])\n",
    "```\n",
    "\n",
    "> **Nuestro modelo predice que este pasajero no sobrevivi√≥.**\n",
    "\n",
    "### Guardar el modelo\n",
    "Este √∫ltimo paso es necesario para la siguiente lecci√≥n en la que pondremos nuestro modelo en producci√≥n. Usaremos un paquete de Python llamado Pickle, el cual nos permite serializar (guardar) objetos de Python en un archivo para luego poder cargarlos y utilizarlos en diferentes entornos, como una API o una aplicaci√≥n web.\n",
    "\n",
    "Pickle es particularmente √∫til cuando queremos guardar modelos entrenados o cualquier otro objeto complejo de Python. Al guardar el pipeline con Pickle, nos aseguramos de que todas las transformaciones de datos y el modelo en s√≠ se conserven tal como fueron entrenados, permiti√©ndonos hacer predicciones consistentes con nuevos datos en producci√≥n sin necesidad de volver a aplicar las mismas transformaciones manualmente.\n",
    "\n",
    "Si no has importado pickle, hazlo ahora\n",
    "```python\n",
    "import pickle\n",
    "```\n",
    "Finalmente, guarda el modelo:\n",
    "```python\n",
    "with open('modelo.pkl', 'wb') as archivo_estimador:\n",
    "    pickle.dump(mejor_estimador, archivo_estimador)\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "084d8c1b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== Rendimiento de los modelos ===\n",
      "                               Modelo  Precisi√≥n\n",
      "0                   Clasificador LGBM     0.8492\n",
      "1  Clasificador de Bosques Aleatorios     0.8380\n",
      "2                Clasificador XGBoost     0.8156\n",
      "3   Clasificador de Gradient Boosting     0.8045\n",
      "4   Clasificador K‚ÄëNearest Neighbours     0.7989\n",
      "5                    Clasificador SVM     0.7989\n",
      "6               Clasificador AdaBoost     0.7989\n",
      "7   Clasificador de √Årbol de Decisi√≥n     0.7989\n",
      "8                 Regresi√≥n Log√≠stica     0.7933\n",
      "9            Clasificador Naive Bayes     0.7598\n",
      "\n",
      "=== Mejor modelo encontrado ===\n",
      "Modelo: Clasificador LGBM\n",
      "Precisi√≥n: 0.8492\n",
      "\n",
      "‚úÖ Modelo guardado en: archivo_estimador.pkl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\mel_f\\Music\\Aprendizaje Supervisado Hybridge\\Aprendizaje-Supervisado\\nombre_proyecto\\Lib\\site-packages\\sklearn\\utils\\validation.py:2749: UserWarning: X does not have valid feature names, but LGBMClassifier was fitted with feature names\n",
      "  warnings.warn(\n",
      "c:\\Users\\mel_f\\Music\\Aprendizaje Supervisado Hybridge\\Aprendizaje-Supervisado\\nombre_proyecto\\Lib\\site-packages\\xgboost\\training.py:183: UserWarning: [19:49:10] WARNING: C:\\actions-runner\\_work\\xgboost\\xgboost\\src\\learner.cc:738: \n",
      "Parameters: { \"use_label_encoder\" } are not used.\n",
      "\n",
      "  bst.update(dtrain, iteration=i, fobj=obj)\n"
     ]
    }
   ],
   "source": [
    "#  DEFINICI√ìN DE MODELOS Y REJILLAS DE HYPER‚ÄëPAR√ÅMETROS\n",
    "modelos = {\n",
    "    # Regresi√≥n log√≠stica (solo como referencia)\n",
    "    \"Regresi√≥n Log√≠stica\": {\n",
    "        \"modelo\": LogisticRegression(max_iter=500, solver=\"lbfgs\"),\n",
    "        \"parametros\": {\"C\": [0.01, 0.1, 1, 10]},\n",
    "    },\n",
    "    # SVM\n",
    "    \"Clasificador SVM\": {\n",
    "        \"modelo\": SVC(),\n",
    "        \"parametros\": {\n",
    "            \"C\": [0.1, 1, 10],\n",
    "            \"kernel\": [\"linear\", \"rbf\"],\n",
    "            \"gamma\": [\"scale\", \"auto\"],\n",
    "        },\n",
    "    },\n",
    "    # K‚ÄëNearest Neighbours\n",
    "    \"Clasificador K‚ÄëNearest Neighbours\": {\n",
    "        \"modelo\": KNeighborsClassifier(),\n",
    "        \"parametros\": {\"n_neighbors\": [3, 5, 7, 9], \"weights\": [\"uniform\", \"distance\"]},\n",
    "    },\n",
    "    # √Årbol de decisi√≥n\n",
    "    \"Clasificador de √Årbol de Decisi√≥n\": {\n",
    "        \"modelo\": DecisionTreeClassifier(),\n",
    "        \"parametros\": {\n",
    "            \"max_depth\": [None, 5, 10, 20],\n",
    "            \"min_samples_split\": [2, 5, 10],\n",
    "        },\n",
    "    },\n",
    "    # Bosques aleatorios\n",
    "    \"Clasificador de Bosques Aleatorios\": {\n",
    "        \"modelo\": RandomForestClassifier(),\n",
    "        \"parametros\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"max_depth\": [None, 10, 20],\n",
    "            \"min_samples_split\": [2, 5],\n",
    "        },\n",
    "    },\n",
    "    # Gradient Boosting\n",
    "    \"Clasificador de Gradient Boosting\": {\n",
    "        \"modelo\": GradientBoostingClassifier(),\n",
    "        \"parametros\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1, 0.2],\n",
    "            \"max_depth\": [3, 5],\n",
    "        },\n",
    "    },\n",
    "    # AdaBoost\n",
    "    \"Clasificador AdaBoost\": {\n",
    "        \"modelo\": AdaBoostClassifier(),\n",
    "        \"parametros\": {\"n_estimators\": [50, 100, 200], \"learning_rate\": [0.5, 1.0, 1.5]},\n",
    "    },\n",
    "    # LightGBM\n",
    "    \"Clasificador LGBM\": {\n",
    "        \"modelo\": LGBMClassifier(),\n",
    "        \"parametros\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"num_leaves\": [31, 63],\n",
    "        },\n",
    "    },\n",
    "    # XGBoost\n",
    "    \"Clasificador XGBoost\": {\n",
    "        \"modelo\": XGBClassifier(use_label_encoder=False, eval_metric=\"logloss\"),\n",
    "        \"parametros\": {\n",
    "            \"n_estimators\": [100, 200],\n",
    "            \"learning_rate\": [0.05, 0.1],\n",
    "            \"max_depth\": [3, 5],\n",
    "        },\n",
    "    },\n",
    "    # Na√Øve Bayes (Gaussian)\n",
    "    \"Clasificador Naive Bayes\": {\n",
    "        \"modelo\": GaussianNB(),\n",
    "        \"parametros\": {},  # sin hiper‚Äëpar√°metros a buscar\n",
    "    },\n",
    "}\n",
    "\n",
    "#  VARIABLES DE CONTROL\n",
    "puntajes_modelos = []          # Lista con nombre y precisi√≥n de cada modelo\n",
    "mejor_precision = -np.inf     # Mejor precisi√≥n encontrada hasta el momento\n",
    "mejor_modelo = None           # Nombre del modelo con mejor precisi√≥n\n",
    "mejor_estimador = None        # Instancia del mejor modelo (con mejores hp)\n",
    "\n",
    "#  BUCLE DE ENTRENAMIENTO + GRID SEARCH\n",
    "for nombre, info in modelos.items():\n",
    "    # Configuramos GridSearchCV (si la rejilla est√° vac√≠a, simplemente usa el modelo tal cual)\n",
    "    grid_search = GridSearchCV(\n",
    "        estimator=info[\"modelo\"],\n",
    "        param_grid=info[\"parametros\"],\n",
    "        cv=5,\n",
    "        scoring=\"accuracy\",\n",
    "        verbose=0,\n",
    "        n_jobs=-1,\n",
    "    )\n",
    "\n",
    "    # Entrenamos\n",
    "    grid_search.fit(X_train, y_train)\n",
    "\n",
    "    # Predicci√≥n sobre el conjunto de prueba\n",
    "    y_pred = grid_search.predict(X_test)\n",
    "\n",
    "    # M√©trica de evaluaci√≥n\n",
    "    precision = accuracy_score(y_test, y_pred)\n",
    "\n",
    "    # Guardamos resultados\n",
    "    puntajes_modelos.append({\"Modelo\": nombre, \"Precisi√≥n\": precision})\n",
    "\n",
    "    # Actualizamos el mejor modelo si corresponde\n",
    "    if precision > mejor_precision:\n",
    "        mejor_precision = precision\n",
    "        mejor_modelo = nombre\n",
    "        mejor_estimador = grid_search.best_estimator_\n",
    "\n",
    "#  RESUMEN DE RESULTADOS (opcional, pero √∫til)\n",
    "metricas = pd.DataFrame(puntajes_modelos).sort_values(\n",
    "    \"Precisi√≥n\", ascending=False\n",
    ").reset_index(drop=True)\n",
    "\n",
    "print(\"\\n=== Rendimiento de los modelos ===\")\n",
    "print(metricas.round(4))\n",
    "\n",
    "print(\"\\n=== Mejor modelo encontrado ===\")\n",
    "print(f\"Modelo: {mejor_modelo}\")\n",
    "print(f\"Precisi√≥n: {mejor_precision:.4f}\")\n",
    "\n",
    "#  SERIALIZACI√ìN DEL MEJOR MODELO\n",
    "ruta_guardado = \"archivo_estimador.pkl\"\n",
    "with open(ruta_guardado, \"wb\") as f:\n",
    "    pickle.dump(mejor_estimador, f)\n",
    "\n",
    "print(f\"\\n‚úÖ Modelo guardado en: {ruta_guardado}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nombre_proyecto",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
